
input {
  beats {
    port => 5000  # Порт на котором Logstash принимает данные от Filebeat
  }
}

filter {
  # Обработка логов пользователей
  if [type] == "user_actions" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{LOGLEVEL:log_level} - %{NOTSPACE:logger_name} - %{GREEDYDATA:message_text}" }
    }
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }

  # Обработка логов платежей
  if [type] == "payment_actions" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{LOGLEVEL:log_level} - %{NOTSPACE:logger_name} - %{GREEDYDATA:message_text}" }
    }
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }

  # Обработка логов мобильных пользователей
  if [type] == "mobile_detail" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{LOGLEVEL:log_level} - %{NOTSPACE:logger_name} - %{GREEDYDATA:message_text}" }
    }
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }

  # Обработка nginx логов
  if [type] == "nginx" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
  }

  # Обработка docker логов
  if [type] == "docker" {
    json {
      source => "message"
      skip_on_invalid_json => true
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[type]}-%{+YYYY.MM.dd}"  # Создаем индексы по типу лога и дате
    pipeline => "logs_pipeline"  # Опционально, если нужен дополнительный пайплайн
  }
}